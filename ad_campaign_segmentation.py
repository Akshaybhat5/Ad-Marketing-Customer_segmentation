# -*- coding: utf-8 -*-
"""Ad_campaign_segmentation

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CQ7LwMG5vciQyCYem2WroEmW6xY1EO2H
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, plot_confusion_matrix, plot_roc_curve
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

import tensorflow as tf
from tensorflow.keras.initializers import glorot_uniform
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.layers import Activation, Input, Dense, Add

data_2 = pd.read_csv('Customer.csv')

data_2.head()

data_2.info()

data_2.describe()

data_2.isnull().sum()

data_2['CREDIT_LIMIT'] = data_2['CREDIT_LIMIT'].fillna(data_2['CREDIT_LIMIT'].mean())

data_2['MINIMUM_PAYMENTS'] = data_2['MINIMUM_PAYMENTS'].fillna(0)

data_2.isnull().sum()

def check_outliers(data):
    plt.figure(figsize=(20,65))
    for i in range(len(data.columns)):
        plt.subplot(17,1, i+1)
        sns.distplot(data[data.columns[i]],
                     kde_kws = {'color':'red','lw':3},
                     hist_kws = {'color':'black'})
        plt.title(data.columns[i])
    plt.tight_layout()

def heatmap(data, title):
    plt.figure(figsize = (20,15))
    sns.heatmap(data.corr(), annot=True)
    plt.title(title, weight='bold')
    plt.tight_layout()

def scatter_plot_for_variables(data, X, Y, title):
    plt.figure(figsize=(12,12))
    sns.scatterplot(data=data, x = X, y = Y)
    plt.title(title, weight='bold')
    plt.tight_layout()

def scaled_data_form(data):
    scaled_data = StandardScaler()
    data_scaled_2 = scaled_data.fit_transform(data)
    return data_scaled_2

def elbow_method(data):
    values = []
    num = range(1,20)
    for i in num:
        kmeans = KMeans(n_clusters=i)
        kmeans.fit(data)
        values.append(kmeans.inertia_)
    return values

def draw_elbow_method(score,title):
    plt.figure(figsize=(10,5))
    plt.plot(score, 'bo-')
    plt.title(title, weight='bold')
    plt.xlabel('Clusters')
    plt.ylabel('WCSS')
    plt.tight_layout()

def principal_component_analysis(val, data):
    pca = PCA(n_components=val)
    values = pca.fit_transform(data)
    return values

def draw_clusters(data,vol):
    for i in data.columns:
        plt.figure(figsize = (25,5))
        for j in range(vol):
            plt.subplot(1, vol, j+1)
            cluster = data[data['cluster']==j]
            cluster[i].hist(bins=20)
            plt.title('{}\n{}'.format(i, j))
    plt.tight_layout()   

def data_with_clos(data, name_of_the_label):
    with_cluster = pd.concat([data, pd.DataFrame({'cluster':name_of_the_label})],axis = 1)
    return with_cluster     
        
def convert_pca_dataframe(data, name_of_the_values):
    dats = pd.concat([data, pd.DataFrame({'cluster':name_of_the_values})],axis=1)
    return dats

def plot_for_segmentation(dataa,X, Y, mon):
    plt.figure(figsize=(10,6))
    ask = input('enter the number of clusters: ')
    ask = int(ask)
    if ask == 8:
        sns.scatterplot(data=dataa, x = X, y  = Y, hue=mon, palette=['red','green','blue','black','yellow','maroon','pink','violet'])
        plt.title('CUSTOMER SEGMENTATION WITH {} CLUSTERS'.format(ask), weight='bold')
    elif ask == 4:
        sns.scatterplot(data=dataa, x = X, y  = Y, hue=mon, palette=['red','green','blue','black'])
        plt.title('CUSTOMER SEGMENTATION WITH {} CLUSTERS'.format(ask), weight='bold')

heatmap(data_2, 'HEAT-MAP')

check_outliers(data_2)

scatter_plot_for_variables(data_2,'CASH_ADVANCE_TRX','BALANCE','BALANCE AND TRANSACTION')

data_fully_scaled = scaled_data_form(data_2)

data_fully_scaled

score_1 = elbow_method(data_2)

score_1

draw_elbow_method(score_1,'ELBOW-METHOD')

kmeans = KMeans(n_clusters=8)
kmeans.fit(data_fully_scaled)

labels = kmeans.labels_

labels

data_cluster = data_with_clos(data_2, labels)

data_cluster

draw_clusters(data_cluster,8)

pca_df_2

pca_df_3 = principal_component_analysis(2, data_fully_scaled)

pca_df_3

pca_df_3 = pd.DataFrame(data = pca_df_3, columns=['pca_1','pca_2'])

pca_df_3

pca_df_3 = convert_pca_dataframe(pca_df_3, labels)

pca_df_3

plot_for_segmentation(pca_df_3,'pca_1','pca_2','cluster')

# Model Architecture
input_shape = Input(shape=(17,))

X = Dense(7, activation='relu') (input_shape)
X = Dense(500, activation='relu', kernel_initializer='glorot_uniform') (X)
X = Dense(500, activation='relu', kernel_initializer='glorot_uniform') (X)
X = Dense(2000, activation='relu', kernel_initializer='glorot_uniform') (X)

# encoded_layer
encoded = Dense(11, activation='relu', kernel_initializer='glorot_uniform') (X)

X = Dense(2000, activation='relu', kernel_initializer='glorot_uniform') (encoded)
X = Dense(500, activation='relu', kernel_initializer='glorot_uniform') (X)

# decoded layer
decoded = Dense(17, activation='relu') (X)

auto_encode_2 = Model(input_shape, decoded)

encoded_2 = Model(input_shape, encoded)

auto_encode_2.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])

history_2 = auto_encode_2.fit(data_fully_scaled, data_fully_scaled, batch_size=108, epochs=100, verbose=1)

pred = encoded_2.predict(data_fully_scaled)

pred

plt.plot(history_2.history['accuracy'],'bo-')
plt.title('Accuracy', weight='bold');

plt.plot(history_2.history['loss'],'bo-')
plt.title('Loss', weight='bold');

score_3 = elbow_method(pred)

elbow_draw(score_3,'ELBOW')

kmeans = KMeans(n_clusters=4)
kmeans.fit(pred)

labeL_2 = kmeans.labels_

labeL_2

sns.countplot(labeL_2)

data_cluster_2 = data_with_clos(data_2, labeL_2)

data_cluster_2

pca_df_4 = principal_component_analysis(2,pred)

pca_df_4

pca_df_4 = pd.DataFrame(data = pca_df_4, columns=['pca_1','pca_2'])

pca_df_4

pca_df_4 = convert_pca_dataframe(pca_df_4, labeL_2)

pca_df_4

plot_for_segmentation(pca_df_4, 'pca_1','pca_2','cluster')

